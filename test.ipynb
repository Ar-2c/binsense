{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ec94e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil, random\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "DATA_DIR = Path(\"dataset\")\n",
    "SPLIT_DIR = Path(\"data_split\")\n",
    "CLASSES = [\"Tom\", \"Halvfull\", \"Full\", \"Overfull\"]  # ändra här om dina mappnamn skiljer sig\n",
    "\n",
    "# skapa målmapp\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for c in CLASSES:\n",
    "        (SPLIT_DIR / split / c).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# proportioner\n",
    "train_p, val_p, test_p = 0.70, 0.15, 0.15\n",
    "\n",
    "for c in CLASSES:\n",
    "    imgs = sorted([p for p in (DATA_DIR / c).glob(\"*\") if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]])\n",
    "    random.shuffle(imgs)\n",
    "    n = len(imgs)\n",
    "    n_train = int(n * train_p)\n",
    "    n_val   = int(n * val_p)\n",
    "    n_test  = n - n_train - n_val\n",
    "\n",
    "    splits = {\n",
    "        \"train\": imgs[:n_train],\n",
    "        \"val\":   imgs[n_train:n_train+n_val],\n",
    "        \"test\":  imgs[n_train+n_val:]\n",
    "    }\n",
    "    for split, files in splits.items():\n",
    "        for src in files:\n",
    "            dst = SPLIT_DIR / split / c / src.name\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "sum(len(list((SPLIT_DIR/s/c).glob(\"*\"))) for s in [\"train\",\"val\",\"test\"] for c in CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407bc06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train {'Tom': 17, 'Halvfull': 17, 'Full': 17, 'Overfull': 17}\n",
      "val {'Tom': 3, 'Halvfull': 3, 'Full': 3, 'Overfull': 3}\n",
      "test {'Tom': 5, 'Halvfull': 5, 'Full': 5, 'Overfull': 5}\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    counts = {c: len(list((SPLIT_DIR/split/c).glob(\"*\"))) for c in CLASSES}\n",
    "    print(split, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8edcf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Klasser: {0: 'Full', 1: 'Halvfull', 2: 'Overfull', 3: 'Tom'}\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\arash/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 47.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train 0.7704 | val 3.9919\n",
      "Epoch 02 | train 0.6629 | val 2.0795\n",
      "Epoch 03 | train 0.2960 | val 0.4152\n",
      "Epoch 04 | train 0.2817 | val 0.2368\n",
      "Epoch 05 | train 0.0605 | val 0.3472\n",
      "Epoch 06 | train 0.1332 | val 0.3469\n",
      "Epoch 07 | train 0.0979 | val 1.2416\n",
      "Epoch 08 | train 0.1429 | val 0.1116\n",
      "Epoch 09 | train 0.2013 | val 2.2886\n",
      "Epoch 10 | train 0.3089 | val 1.2215\n",
      "Epoch 11 | train 0.2765 | val 3.0701\n",
      "Epoch 12 | train 0.0797 | val 1.3474\n",
      "Epoch 13 | train 0.0465 | val 1.3682\n",
      "Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install torch torchvision scikit-learn\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# transforms\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9,1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# datasets\n",
    "train_ds = datasets.ImageFolder(SPLIT_DIR/\"train\", transform=train_tf)\n",
    "val_ds   = datasets.ImageFolder(SPLIT_DIR/\"val\",   transform=eval_tf)\n",
    "test_ds  = datasets.ImageFolder(SPLIT_DIR/\"test\",  transform=eval_tf)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "idx_to_class = {v:k for k,v in train_ds.class_to_idx.items()}\n",
    "print(\"Klasser:\", idx_to_class)\n",
    "\n",
    "# modell\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(CLASSES))\n",
    "model.to(device)\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# träning med enkel early stopping\n",
    "best_val = float(\"inf\")\n",
    "patience, bad = 5, 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for x,y in train_dl:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = crit(logits, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running += loss.item()*x.size(0)\n",
    "    train_loss = running/len(train_ds)\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    vloss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_dl:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = crit(logits, y)\n",
    "            vloss += loss.item()*x.size(0)\n",
    "    val_loss = vloss/len(val_ds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | train {train_loss:.4f} | val {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        bad = 0\n",
    "        torch.save(model.state_dict(), \"bin_classifier_resnet18.pt\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# ladda bästa\n",
    "model.load_state_dict(torch.load(\"bin_classifier_resnet18.pt\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fc1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Full       1.00      0.60      0.75         5\n",
      "    Halvfull       0.71      1.00      0.83         5\n",
      "    Overfull       1.00      1.00      1.00         5\n",
      "         Tom       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.93      0.90      0.90        20\n",
      "weighted avg       0.93      0.90      0.90        20\n",
      "\n",
      "Confusion matrix:\n",
      " [[3 2 0 0]\n",
      " [0 5 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 0 5]]\n",
      "Recall(Töm nu): 0.800\n"
     ]
    }
   ],
   "source": [
    "# prediktioner på test\n",
    "all_y, all_p = [], []\n",
    "with torch.no_grad():\n",
    "    for x,y in test_dl:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy()\n",
    "        all_p.extend(preds.tolist())\n",
    "        all_y.extend(y.numpy().tolist())\n",
    "\n",
    "all_y = np.array(all_y)\n",
    "all_p = np.array(all_p)\n",
    "\n",
    "print(\"Classification report:\\n\",\n",
    "      classification_report(all_y, all_p, target_names=[idx_to_class[i] for i in range(len(CLASSES))]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_y, all_p)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# KPI: Recall för \"Töm nu\" (Full + Overfull)\n",
    "cls_to_idx = train_ds.class_to_idx\n",
    "full_idx = cls_to_idx[\"Full\"]\n",
    "over_idx = cls_to_idx[\"Overfull\"]\n",
    "tomnu_mask = np.isin(all_y, [full_idx, over_idx])\n",
    "\n",
    "tp = np.sum((np.isin(all_p, [full_idx, over_idx])) & tomnu_mask)\n",
    "fn = np.sum((~np.isin(all_p, [full_idx, over_idx])) & tomnu_mask)\n",
    "recall_tomnu = tp / (tp + fn + 1e-9)\n",
    "print(f\"Recall(Töm nu): {recall_tomnu:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3377cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Full', 0.9849173426628113, True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "infer_tf = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
    "\n",
    "def predict_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = infer_tf(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        pred = logits.argmax(1).item()\n",
    "        probs = torch.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "    klass = idx_to_class[pred]\n",
    "    tomnu = klass in [\"Full\", \"Overfull\"]\n",
    "    return klass, float(probs[pred]), tomnu\n",
    "\n",
    "# exempel\n",
    "predict_image(\"dataset/Full/Gemini_Generated_Image_f6x6lhf6x6lhf6x6.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
